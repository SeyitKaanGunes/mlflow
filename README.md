# MLflow Experiment Tracking Repository

Bu repo, makine Ã¶ÄŸrenmesi projelerinde **deney takibi**, **model versiyonlama**, **artifakt yÃ¶netimi** ve **tekrarlanabilir MLOps sÃ¼reÃ§leri** oluÅŸturmak iÃ§in yapÄ±landÄ±rÄ±lmÄ±ÅŸ bir MLflow altyapÄ±sÄ± iÃ§erir. Kod tabanÄ±, sade bir proje yapÄ±sÄ± Ã¼zerinde MLflowâ€™un yerel (local) kullanÄ±mÄ±na odaklanÄ±r.

---

## ğŸš€ AmaÃ§

Bu proje, model geliÅŸtirme sÃ¼recindeki tÃ¼m deneyleri merkezi bir yapÄ±da takip etmeyi saÄŸlar:

- Deney parametreleri ve metriklerin kaydÄ±  
- Modellerin otomatik versiyonlanmasÄ±  
- Yerel MLflow UI ile takip  
- Kolay test, geliÅŸtirme ve demo ortamÄ±  

MLflowâ€™u â€œtek dosyalÄ±k minimal bir tracking serverâ€ olarak kullanmak isteyenler iÃ§in idealdir.

---

## ğŸ“ Proje YapÄ±sÄ±

```
mlflow/
â”‚
â”œâ”€â”€ mlflow.db           # SQLite backend-store (MLflow meta)
â”œâ”€â”€ mlruns/             # MLflow artifact store
â”œâ”€â”€ .env                # Ortam deÄŸiÅŸkenleri (opsiyonel)
â”œâ”€â”€ train.py            # Deneme amaÃ§lÄ± MLflow log script'i
â””â”€â”€ README.md           # Bu dosya
```

---

## ğŸ”§ Kurulum

### 1) Gerekli paketleri kur

```bash
pip install -r requirements.txt
```

veya

```bash
pip install mlflow
```

---

## ğŸ MLflow Tracking Server BaÅŸlatma

Repo kÃ¶k dizininde ÅŸu komutu Ã§alÄ±ÅŸtÄ±r:

```bash
mlflow server   --backend-store-uri sqlite:///mlflow.db   --default-artifact-root ./mlruns   --host 127.0.0.1   --port 5000
```

ArayÃ¼z adresi:  
ğŸ‘‰ http://127.0.0.1:5000

---

## ğŸ§ª Ã–rnek EÄŸitim Scripti

Bu repo iÃ§inde basit bir MLflow test scriptâ€™i bulunuyor: `train.py`

Ã‡alÄ±ÅŸtÄ±rmak iÃ§in:

```bash
python train.py
```

Script, MLflow Ã¼zerinde aÅŸaÄŸÄ±dakileri otomatik loglar:

- Parametreler  
- Metrikler  
- Model (pickle formatÄ±nda)  
- Ã‡Ä±ktÄ±lar  

---

## ğŸ” Deney KayÄ±tlarÄ±nÄ± GÃ¶rÃ¼ntÃ¼leme

Ã‡alÄ±ÅŸan MLflow server Ã¼zerinden:

- Run ID
- Parametreler
- Metrikler
- Artifactâ€™ler (model dosyasÄ± vs.)

hepsini UIâ€™dan inceleyebilirsin.

---

## ğŸ“¦ Model YÃ¼kleme (Prediction)

KaydedilmiÅŸ bir modeli yÃ¼klemek iÃ§in:

```python
import mlflow.pyfunc

model = mlflow.pyfunc.load_model("runs:/<RUN_ID>/model")
pred = model.predict(input_data)
```

---

## ğŸ§  Teknoloji Stack

- **Python 3.11+**
- **MLflow**
- **SQLite backend store**
- **Local artifact storage (mlruns/)**

---

## ğŸ‘¤ GeliÅŸtirici

**Seyit Kaan GÃ¼neÅŸ**  
AI / ML Developer  
GitHub: https://github.com/SeyitKaanGunes

---

Bu repo, â€œminir MLflow altyapÄ±sÄ± isteyenler imal ama etkiliâ€ biÃ§in hazÄ±rlanmÄ±ÅŸtÄ±r.
Daha geliÅŸmiÅŸ bir pipeline (DVC, Docker, model registry, CI/CD) eklemek istersen yapÄ± buna uygun ÅŸekilde geniÅŸletilebilir.

## ğŸ” Adalet, GÃ¼venlik, Governance ve SBOM

- Fairlearn: Grup bazlÄ± adalet ve parite farklarÄ± iÃ§in `python assurance_suite.py --skip-giskard --skip-credo --skip-sbom` komutunu Ã§alÄ±ÅŸtÄ±r; Ã§Ä±ktÄ±lar `artifacts/assurance/fairlearn/` altÄ±nda.
- Giskard (gÃ¼venlik/saÄŸlamlÄ±k): Python 3.10/3.11 ortamÄ±nda `pip install giskard` sonrasÄ± `python assurance_suite.py --skip-fairlearn --skip-credo --skip-sbom` komutuyla Ã§Ä±ktÄ±lar `artifacts/assurance/giskard/` altÄ±nda oluÅŸur. 3.13 iÃ§in GISKARD_SKIPPED.txt notunu kontrol et.
- Credo AI (yÃ¶netim/uyum): `python assurance_suite.py` governance taslaÄŸÄ±nÄ± `artifacts/assurance/governance/` klasÃ¶rÃ¼ne yazar. Tam Lens deneyimi iÃ§in Python 3.10/3.11 + `pip install credoai-lens` kullan.
- CycloneDX SBOM: `python assurance_suite.py --skip-fairlearn --skip-giskard --skip-credo` veya doÄŸrudan `cyclonedx-bom --format json -o artifacts/assurance/sbom/sbom.json` komutu ile tedarik zinciri listesi yarat.
- Hepsi bir arada: `python assurance_suite.py` komutu adalet, gÃ¼venlik (kuruluysa), governance taslaÄŸÄ± ve SBOM Ã§Ä±ktÄ±sÄ± Ã¼retir; Ã¶zet `artifacts/assurance/assurance_summary.json` dosyasÄ±nda.
